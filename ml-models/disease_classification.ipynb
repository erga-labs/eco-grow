{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cuda'\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some constants\n",
    "TRAIN_IMAGE_FOLDER = \"dataset/disease-classification/train\"\n",
    "VALID_IMAGE_FOLDER = \"dataset/disease-classification/valid\"\n",
    "SAVE_MODEL_FOLDER = \"saved-models/disease-classification\"\n",
    "IMAGE_SIZE = 224\n",
    "CNN_FILTERS = [16, 32, 64, 64]\n",
    "DNN_FEATURES = [128, 128, 1] # must end with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Sequential                               [1, 1]                    --\n",
      "├─Sequential: 1-1                        [1, 64, 14, 14]           --\n",
      "│    └─Sequential: 2-1                   [1, 16, 112, 112]         --\n",
      "│    │    └─Conv2d: 3-1                  [1, 16, 224, 224]         448\n",
      "│    │    └─ReLU: 3-2                    [1, 16, 224, 224]         --\n",
      "│    │    └─MaxPool2d: 3-3               [1, 16, 112, 112]         --\n",
      "│    └─Sequential: 2-2                   [1, 32, 56, 56]           --\n",
      "│    │    └─Conv2d: 3-4                  [1, 32, 112, 112]         4,640\n",
      "│    │    └─ReLU: 3-5                    [1, 32, 112, 112]         --\n",
      "│    │    └─MaxPool2d: 3-6               [1, 32, 56, 56]           --\n",
      "│    └─Sequential: 2-3                   [1, 64, 28, 28]           --\n",
      "│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           18,496\n",
      "│    │    └─ReLU: 3-8                    [1, 64, 56, 56]           --\n",
      "│    │    └─MaxPool2d: 3-9               [1, 64, 28, 28]           --\n",
      "│    └─Sequential: 2-4                   [1, 64, 14, 14]           --\n",
      "│    │    └─Conv2d: 3-10                 [1, 64, 28, 28]           36,928\n",
      "│    │    └─ReLU: 3-11                   [1, 64, 28, 28]           --\n",
      "│    │    └─MaxPool2d: 3-12              [1, 64, 14, 14]           --\n",
      "├─Flatten: 1-2                           [1, 12544]                --\n",
      "├─Sequential: 1-3                        [1, 1]                    --\n",
      "│    └─Linear: 2-5                       [1, 128]                  1,605,760\n",
      "│    └─Sequential: 2-6                   [1, 128]                  --\n",
      "│    │    └─ReLU: 3-13                   [1, 128]                  --\n",
      "│    │    └─Linear: 3-14                 [1, 128]                  16,512\n",
      "│    └─Sequential: 2-7                   [1, 1]                    --\n",
      "│    │    └─ReLU: 3-15                   [1, 128]                  --\n",
      "│    │    └─Linear: 3-16                 [1, 1]                    129\n",
      "==========================================================================================\n",
      "Total params: 1,682,913\n",
      "Trainable params: 1,682,913\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 169.26\n",
      "==========================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 11.64\n",
      "Params size (MB): 6.73\n",
      "Estimated Total Size (MB): 18.98\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def make_model():\n",
    "\n",
    "    def make_conv_block(idx):\n",
    "        in_channels = 3 if idx == 0 else CNN_FILTERS[idx-1]\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels=CNN_FILTERS[idx], kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "\n",
    "    cnn_layers = nn.Sequential(*(\n",
    "        make_conv_block(idx)\n",
    "        for idx in range(len(CNN_FILTERS))\n",
    "    ))\n",
    "\n",
    "    final_size = IMAGE_SIZE // 2**len(CNN_FILTERS)\n",
    "\n",
    "    classifier_layers = nn.Sequential(\n",
    "        nn.Linear(final_size*final_size*CNN_FILTERS[-1], out_features=DNN_FEATURES[0]),\n",
    "        *(\n",
    "            nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(DNN_FEATURES[i], out_features=DNN_FEATURES[i+1]),\n",
    "            )\n",
    "            for i in range(len(DNN_FEATURES) - 1)\n",
    "        )\n",
    "        # no sigmoid due to logits loss\n",
    "    )\n",
    "\n",
    "    return nn.Sequential(\n",
    "        cnn_layers,\n",
    "        nn.Flatten(),\n",
    "        classifier_layers,\n",
    "    )\n",
    "\n",
    "\n",
    "temp_model = make_model()\n",
    "print(summary(temp_model, input_size=(1, 3, IMAGE_SIZE, IMAGE_SIZE)))\n",
    "del temp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, repeats=1, for_training=True):\n",
    "        root_dir = TRAIN_IMAGE_FOLDER if for_training else VALID_IMAGE_FOLDER\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToImage(),\n",
    "            transforms.RandomCrop(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomAffine(degrees=180, translate=(0.2, 0.2), scale=(0.7, 1.3)),\n",
    "            transforms.ToDtype(torch.float32, scale=True),\n",
    "        ]) if for_training else transforms.Compose([\n",
    "            transforms.ToImage(),\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.ToDtype(torch.float32, scale=True),\n",
    "        ])\n",
    "\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for dir_name in os.listdir(root_dir):\n",
    "            dir_path = os.path.join(root_dir, dir_name)\n",
    "            label = int('healthy' in dir_name)\n",
    "\n",
    "            for file_name in os.listdir(dir_path):\n",
    "                file_path = os.path.join(dir_path, file_name)\n",
    "                self.samples.append((file_path, label))\n",
    "\n",
    "        self.samples *= repeats\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.samples[index]\n",
    "        img = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(batch_size, dataset_repeat, epochs):\n",
    "    from multiprocessing import cpu_count\n",
    "\n",
    "    dataset = CustomDataset(dataset_repeat)\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cpu_count(),\n",
    "        pin_memory=(device != 'cpu'),\n",
    "    )\n",
    "\n",
    "    print(f\"Healthy Count: {sum(s[1] == 1 for s in dataset.samples)}\")\n",
    "    print(f\"Disease Count: {sum(s[1] == 0 for s in dataset.samples)}\")\n",
    "\n",
    "    model = make_model().to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    AMP_ENABLED = device == 'cuda'\n",
    "    scaler = torch.amp.GradScaler(enabled=AMP_ENABLED)\n",
    "\n",
    "    import math\n",
    "    batches_per_epoch = math.ceil(len(dataset) / batch_size)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "\n",
    "        pbar = tqdm(\n",
    "            dataloader,\n",
    "            total=batches_per_epoch,\n",
    "            unit=\"batches\",\n",
    "            desc=f\"Training for epoch = {epoch+1}\",\n",
    "        )\n",
    "\n",
    "        for bid, (x, y) in enumerate(pbar, start=1):\n",
    "            x = x.to(device)\n",
    "            y = y.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.amp.autocast(device, enabled=AMP_ENABLED):\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs.squeeze(), y)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs.squeeze())\n",
    "            correct += torch.isclose(preds, y.to(preds.dtype), atol=0.1).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            accuracy = correct / total * 100\n",
    "            avg_loss = running_loss / bid\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{avg_loss:.4f}\",\n",
    "                'acc': f\"{accuracy:.2f}%\",\n",
    "                'batch': f\"{bid}/{batches_per_epoch}\"\n",
    "            })\n",
    "\n",
    "    scripted_model = torch.jit.script(model)\n",
    "    scripted_model.save(f\"saved-models/disease-classification/model.pt\")\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(batch_size):\n",
    "    from multiprocessing import cpu_count\n",
    "\n",
    "    dataset = CustomDataset(for_training=False)\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=max(1, cpu_count()-2),\n",
    "        pin_memory=(device != 'cpu'),\n",
    "    )\n",
    "\n",
    "    print(f\"Healthy Count: {sum(s[1] == 1 for s in dataset.samples)}\")\n",
    "    print(f\"Disease Count: {sum(s[1] == 0 for s in dataset.samples)}\")\n",
    "\n",
    "    model = torch.jit.load(f\"saved-models/disease-classification/model.pt\", map_location=device)\n",
    "    model.eval()\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    total_loss = 0.0\n",
    "    correct_over = 0\n",
    "    correct_within = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(\n",
    "        dataloader,\n",
    "        total=len(dataloader),\n",
    "        unit=\"batches\",\n",
    "        desc=f\"Validating Model\",\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bid, (x, y) in enumerate(pbar, start=1):\n",
    "            x = x.to(device)\n",
    "            y = y.float().to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs.squeeze(), y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs.squeeze())\n",
    "            correct_within += torch.isclose(preds, y, atol=0.1).sum().item()\n",
    "            correct_over += ((preds > 0.5) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "            avg_loss = total_loss / bid\n",
    "            accuracy_within = correct_within / total * 100\n",
    "            accuracy_over = correct_over / total * 100\n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{avg_loss:.4f}\",\n",
    "                'acc_within': f\"{accuracy_within:.2f}%\",\n",
    "                'acc_over': f\"{accuracy_over:.2f}%\",\n",
    "                'batch': f\"{bid}/{len(dataloader)}\"\n",
    "            })\n",
    "\n",
    "    print(f\"Validation Loss: {avg_loss:.4f} | Accuracy (within): {accuracy_within:.2f}% | Accuracy (over): {accuracy_over:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy Count: 44588\n",
      "Disease Count: 96002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training for epoch = 1: 100%|██████████| 2197/2197 [01:22<00:00, 26.70batches/s, loss=0.2099, acc=69.10%, batch=2197/2197]\n",
      "Training for epoch = 2: 100%|██████████| 2197/2197 [01:23<00:00, 26.32batches/s, loss=0.0933, acc=88.30%, batch=2197/2197]\n",
      "Training for epoch = 3: 100%|██████████| 2197/2197 [01:23<00:00, 26.22batches/s, loss=0.0728, acc=91.18%, batch=2197/2197]\n",
      "Training for epoch = 4: 100%|██████████| 2197/2197 [01:23<00:00, 26.16batches/s, loss=0.0589, acc=92.94%, batch=2197/2197]\n",
      "Training for epoch = 5: 100%|██████████| 2197/2197 [01:24<00:00, 26.04batches/s, loss=0.0499, acc=94.01%, batch=2197/2197]\n"
     ]
    }
   ],
   "source": [
    "config = {\"batch_size\": 64, \"dataset_repeat\": 2, \"epochs\": 5}\n",
    "train_and_save(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy Count: 5572\n",
      "Disease Count: 12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Model: 100%|██████████| 138/138 [00:06<00:00, 19.86batches/s, loss=0.1881, acc_within=86.27%, acc_over=93.36%, batch=138/138]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1881 | Accuracy (within): 86.27% | Accuracy (over): 93.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
